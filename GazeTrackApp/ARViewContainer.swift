//  ARViewContainer.swift
//  Eye-Tracker
//
//  Created by Haoran Zhang on 03/07 2025.
//
//  A AR view container that handles face tracking and eye gaze detection
//  This component integrates ARKit face tracking to enable eye gaze tracking
//  and facial expression detection features
//

import SwiftUI
import ARKit
import RealityKit

struct ARViewContainer: UIViewRepresentable {
    @Binding var eyeGazeActive: Bool
    @Binding var lookAtPoint: CGPoint?
    @Binding var isWinking: Bool
    @StateObject var calibrationManager: CalibrationManager
    @StateObject var measurementManager: MeasurementManager
    @Binding var smoothingIntensity: Float
    @Binding var arView: CustomARView?
    
    func makeUIView(context: Context) -> CustomARView {
        let customARView = CustomARView(
            eyeGazeActive: $eyeGazeActive,
            lookAtPoint: $lookAtPoint,
            isWinking: $isWinking,
            calibrationManager: calibrationManager,
            measurementManager: measurementManager,
            smoothingIntensity: $smoothingIntensity
        )
        
        // å°†ARViewå®ä¾‹å­˜å‚¨åˆ°ç»‘å®šä¸­
        DispatchQueue.main.async {
            arView = customARView
        }
        
        return customARView
    }
    
    func updateUIView(_ uiView: CustomARView, context: Context) {}
}

class CustomARView: ARView, ARSessionDelegate {
    @Binding var eyeGazeActive: Bool
    @Binding var lookAtPoint: CGPoint?
    @Binding var isWinking: Bool
    var calibrationManager: CalibrationManager
    var measurementManager: MeasurementManager
    @Binding var smoothingIntensity: Float
    
    // ç®€åŒ–çš„çœ¨çœ¼æ„ŸçŸ¥Kalmanæ»¤æ³¢å™¨
    private var gazeKalmanFilter = GazeKalmanFilter()
    private var lastUpdateTime: TimeInterval = 0
    private var isSmoothing: Bool = false
    private var lastBlinkCheck: Float = 0
    private let baseMeasurementNoise: Float = 2.0
    
    init(eyeGazeActive: Binding<Bool>,
         lookAtPoint: Binding<CGPoint?>,
         isWinking: Binding<Bool>,
         calibrationManager: CalibrationManager,
         measurementManager: MeasurementManager,
         smoothingIntensity: Binding<Float>) {
        self.calibrationManager = calibrationManager
        self.measurementManager = measurementManager
        _eyeGazeActive = eyeGazeActive
        _lookAtPoint = lookAtPoint
        _isWinking = isWinking
        _smoothingIntensity = smoothingIntensity
        super.init(frame: .zero)
        self.session.delegate = self
        calibrationManager.arView = self
        let configuration = ARFaceTrackingConfiguration()
        self.session.run(configuration)
    }
    

   
    func session(_ session: ARSession, didUpdate anchors: [ARAnchor]) {
        guard let faceAnchor = anchors.compactMap({ $0 as? ARFaceAnchor }).first else {
            return
        }
        
        // å¦‚æœåœ¨æ ¡å‡†æ¨¡å¼ä¸‹ï¼Œæ”¶é›†æ ¡å‡†æ•°æ®
        if calibrationManager.isCalibrating {
            calibrationManager.collectGazeVector(from:faceAnchor)
        }
        
        // æ›´æ–°lookAtPointç”¨äºæ ¡å‡†å’Œæµ‹é‡æ¨¡å¼ï¼ˆæ— è®ºæ˜¯å¦åœ¨è¿½è¸ªæ¨¡å¼ä¸‹éƒ½éœ€è¦åŸºç¡€çš„gaze pointï¼‰
        if !eyeGazeActive || (eyeGazeActive && !calibrationManager.calibrationCompleted) || calibrationManager.isCalibrating {
            updateDetectGazePoint(faceAnchor: faceAnchor)
        }
        
        // å¦‚æœåœ¨æµ‹é‡æ¨¡å¼ä¸‹ï¼Œæ”¶é›†æµ‹é‡æ•°æ®
        if measurementManager.isMeasuring && measurementManager.showCalibrationPoint {
            if let point = lookAtPoint {
                measurementManager.collectMeasurementPoint(point)
            }
        }
        
        // å¦‚æœåœ¨8å­—å½¢è½¨è¿¹æµ‹é‡æ¨¡å¼ä¸‹ï¼Œæ”¶é›†è½¨è¿¹æµ‹é‡æ•°æ®
        if measurementManager.isTrajectoryMeasuring {
            if let point = lookAtPoint,
               let cameraTransform = session.currentFrame?.camera.transform {
                // è®¡ç®—å®é™…çš„é¢éƒ¨åˆ°å±å¹•è·ç¦»
                let faceDistanceToCamera = calculateFaceToScreenDistance(faceAnchor: faceAnchor, cameraTransform: cameraTransform)
                measurementManager.collectTrajectoryMeasurementPoint(point, eyeToScreenDistance: faceDistanceToCamera)
            }
        }
        
        // å¦‚æœåœ¨è¿½è¸ªæ¨¡å¼ä¸‹ï¼Œä¸”æ ¡å‡†å®Œæˆï¼Œä½¿ç”¨æ ¡å‡†åçš„æ¨¡å‹
        if eyeGazeActive {
            if calibrationManager.calibrationCompleted{
                #if DEBUG
                if arc4random_uniform(300) == 0 {
                    print("ğŸ”´ [GAZE TRACKING] ä½¿ç”¨æ ¡å‡†åçš„æ¨¡å‹è¿›è¡Œçœ¼åŠ¨è¿½è¸ª")
                    print("ğŸ”´ [GAZE TRACKING] æ ¡å‡†çŠ¶æ€: \(calibrationManager.calibrationCompleted)")
                }
                #endif
                calibrationManager.predictScreenPoint(from:faceAnchor)
            } else {
                #if DEBUG
                if arc4random_uniform(300) == 0 {
                    print("ğŸŸ¡ [GAZE TRACKING] æœªå®Œæˆæ ¡å‡†ï¼Œä½¿ç”¨åŸå§‹gaze point")
                    print("ğŸŸ¡ [GAZE TRACKING] æ ¡å‡†çŠ¶æ€: \(calibrationManager.calibrationCompleted)")
                }
                #endif
            }
        }
//        self.configureDebugOptions()
//        self.showLocalLookVector(from: faceAnchor)
        detectWink(faceAnchor: faceAnchor)
        detectEyebrowRaise(faceAnchor: faceAnchor)
    }
    
    func detectGazePoint(faceAnchor: ARFaceAnchor)->CGPoint {
        let lookAtPoint = faceAnchor.lookAtPoint
        let focusPoint = detectGazePointAfterCalibration(faceAnchor: faceAnchor, overrideLookAtPoint: lookAtPoint)
        return focusPoint
    }

    func detectGazePointAfterCalibration(faceAnchor: ARFaceAnchor, overrideLookAtPoint: SIMD3<Float>)-> CGPoint {
        // get the lookAtPoint from faceAnchor local coordinate
        let lookAtPoint = overrideLookAtPoint
        guard let cameraTransform = session.currentFrame?.camera.transform else {
            return .zero
        }
        
        // convert the lookAtPoint from local coordinate into world coordinate
        let lookAtPointInWorld = faceAnchor.transform * simd_float4(lookAtPoint, 1)

        // convert the lookAtPoint from world coordinate into camera coordinate
        let lookAtPointInCamera = simd_mul(simd_inverse(cameraTransform), lookAtPointInWorld)
        
        // è®¡ç®—focus pointåœ¨æ‰‹æœºå±å¹•çš„åæ ‡ï¼ˆæ”¯æŒæ¨ªç«–å±ï¼‰
        let screenX: Float
        let screenY: Float
        
        if Device.isCameraOnLeft {
            // æ‘„åƒå¤´åœ¨å·¦ä¾§ï¼ˆlandscapeRightï¼‰
            let orientationAwarePhysicalSize = Device.orientationAwareScreenSize
            let frameSize = Device.frameSize
            screenX = lookAtPointInCamera.x / (Float(orientationAwarePhysicalSize.width) / 2) * Float(frameSize.width)
            screenY = -lookAtPointInCamera.y / (Float(orientationAwarePhysicalSize.height) / 2) * Float(frameSize.height)
        } else if Device.isCameraOnRight {
            // æ‘„åƒå¤´åœ¨å³ä¾§ï¼ˆlandscapeLeftï¼‰
            let orientationAwarePhysicalSize = Device.orientationAwareScreenSize
            let frameSize = Device.frameSize
            screenX = -lookAtPointInCamera.x / (Float(orientationAwarePhysicalSize.width) / 2) * Float(frameSize.width)
            screenY = lookAtPointInCamera.y / (Float(orientationAwarePhysicalSize.height) / 2) * Float(frameSize.height)
        } else {
            // Portraitæ¨¡å¼ï¼šä½¿ç”¨åŸæœ‰é€»è¾‘
            screenX = lookAtPointInCamera.y / (Float(Device.screenSize.width) / 2) * Float(Device.frameSize.width)
            screenY = lookAtPointInCamera.x / (Float(Device.screenSize.height) / 2) * Float(Device.frameSize.height)
        }
        
        let rawFocusPoint = CGPoint(
            x: CGFloat(screenX).clamped(to: Ranges.widthRange),
            y: CGFloat(screenY).clamped(to: Ranges.heightRange)
        )
        
        // åº”ç”¨å¢å¼ºç‰ˆKalmanæ»¤æ³¢å™¨è¿›è¡Œå¹³æ»‘å¤„ç†
        let focusPoint = applyKalmanSmoothing(rawPoint: rawFocusPoint, faceAnchor: faceAnchor)
        
        #if DEBUG
        if arc4random_uniform(300) == 0 {
            let safeAreaInsets = Device.getSafeAreaInsets()
            let rawFocusPoint = CGPoint(x: CGFloat(screenX), y: CGFloat(screenY))
            
            
            print("=== çœ¼åŠ¨è¿½è¸ªåæ ‡è½¬æ¢è°ƒè¯• ===")
            print("å½“å‰æ–¹å‘:", Device.isCameraOnLeft ? "æ‘„åƒå¤´åœ¨å·¦" : Device.isCameraOnRight ? "æ‘„åƒå¤´åœ¨å³" : "ç«–å±")
            print("Cameraåæ ‡:", lookAtPointInCamera)
            if Device.isCameraOnLeft {
                let orientationAwarePhysicalSize = Device.orientationAwareScreenSize
                let bounds = UIScreen.main.bounds.size
                print("æ‘„åƒå¤´åœ¨å·¦è®¡ç®—è¯¦æƒ…(ä½¿ç”¨boundså°ºå¯¸):")
                print("  - ç‰©ç†å°ºå¯¸:", orientationAwarePhysicalSize)
                print("  - Xè®¡ç®—: \(lookAtPointInCamera.x) / (\(orientationAwarePhysicalSize.width)/2) * \(bounds.width) = \(screenX)")
                print("  - Yè®¡ç®—: -\(lookAtPointInCamera.y) / (\(orientationAwarePhysicalSize.height)/2) * \(bounds.height) = \(screenY)")
            } else if Device.isCameraOnRight {
                let orientationAwarePhysicalSize = Device.orientationAwareScreenSize
                let bounds = UIScreen.main.bounds.size
                print("æ‘„åƒå¤´åœ¨å³è®¡ç®—è¯¦æƒ…(ä½¿ç”¨boundså°ºå¯¸):")
                print("  - ç‰©ç†å°ºå¯¸:", orientationAwarePhysicalSize)
                print("  - Xè®¡ç®—: -\(lookAtPointInCamera.x) / (\(orientationAwarePhysicalSize.width)/2) * \(bounds.width) = \(screenX)")
                print("  - Yè®¡ç®—: \(lookAtPointInCamera.y) / (\(orientationAwarePhysicalSize.height)/2) * \(bounds.height) = \(screenY)")
            } else {
                print("ç«–å±è®¡ç®—è¯¦æƒ…:")
                print("  - ç‰©ç†å°ºå¯¸:", Device.screenSize)
                print("  - Xè®¡ç®—: \(lookAtPointInCamera.y) / (\(Device.screenSize.width)/2) * \(Device.frameSize.width) = \(screenX)")
                print("  - Yè®¡ç®—: \(lookAtPointInCamera.x) / (\(Device.screenSize.height)/2) * \(Device.frameSize.height) = \(screenY)")
            }
            print("è®¡ç®—åå±å¹•åæ ‡(æœªé™åˆ¶):", rawFocusPoint)
            print("focusPoint:", focusPoint)
            print("æ–¹å‘æ„ŸçŸ¥å±å¹•å°ºå¯¸:", Device.orientationAwareScreenSize)
            print("å®‰å…¨åŒºåŸŸçš„å±å¹•å°ºå¯¸:", Device.frameSize)
            print("å®‰å…¨åŒºåŸŸçš„margin:", "top=\(safeAreaInsets.top), bottom=\(safeAreaInsets.bottom), left=\(safeAreaInsets.left), right=\(safeAreaInsets.right)")
            print("XèŒƒå›´: \(Ranges.widthRange), YèŒƒå›´: \(Ranges.heightRange)")
            print("æ‘„åƒå¤´ä¾§è¾¹ç•Œæ£€æŸ¥:", Device.isCameraOnLeft ? "å·¦ä¾§è¾¹ç•Œ=\(Ranges.widthRange.lowerBound)" : "å³ä¾§è¾¹ç•Œ=\(Ranges.widthRange.upperBound)")
            print("=======================")

        }
        #endif
        
        return focusPoint
    }
    func updateDetectGazePoint(faceAnchor: ARFaceAnchor){
        let focusPoint=detectGazePoint(faceAnchor: faceAnchor)
        DispatchQueue.main.async {
            self.lookAtPoint = focusPoint
        }
    }
    func updateDetectGazePointAfterCalibration(faceAnchor: ARFaceAnchor,overrideLookAtPoint: SIMD3<Float>){
        let focusPoint=detectGazePointAfterCalibration(faceAnchor: faceAnchor,overrideLookAtPoint: overrideLookAtPoint)
        DispatchQueue.main.async {
            self.lookAtPoint = focusPoint
        }
    }
    
    func calculateFaceToScreenDistance(faceAnchor: ARFaceAnchor, cameraTransform: simd_float4x4) -> Float {
        // Calculate face center position in world coordinates
        let faceWorldPosition = faceAnchor.transform.columns.3
        
        // Calculate camera position in world coordinates
        let cameraWorldPosition = cameraTransform.columns.3
        
        // Calculate the distance vector from face to camera
        let distanceVector = simd_float3(
            faceWorldPosition.x - cameraWorldPosition.x,
            faceWorldPosition.y - cameraWorldPosition.y,
            faceWorldPosition.z - cameraWorldPosition.z
        )
        
        // Calculate the magnitude (distance) in meters
        let distanceInMeters = simd_length(distanceVector)
        
        // Convert to centimeters
        let distanceInCentimeters = distanceInMeters * 100.0
        
        return distanceInCentimeters
    }

    func showLocalLookVector(from faceAnchor: ARFaceAnchor) {
        if let oldAnchor = self.scene.anchors.first(where: { $0.name == "localLookVectorAnchor" }) {
            self.scene.anchors.remove(oldAnchor)
        }

        let localLookAt = faceAnchor.lookAtPoint
        let vectorLength = simd_length(localLookAt)
        guard vectorLength > 0.001 else { return }

        // ğŸŸ¢ èµ·ç‚¹çƒä½“ï¼ˆface local åŸç‚¹ï¼‰
        let startSphere = ModelEntity(
            mesh: .generateSphere(radius: 0.05),
            materials: [SimpleMaterial(color: .green, isMetallic: false)]
        )
        startSphere.position = [0, 0, 0]

        // âœ… å°†çƒä½“æ·»åŠ åˆ°ä»¥ faceAnchor.transform ä¸ºå˜æ¢çš„ anchor ä¸Š
        let anchor = AnchorEntity()
        anchor.transform.matrix = faceAnchor.transform
        anchor.name = "localLookVectorAnchor"
        anchor.addChild(startSphere)

        self.scene.anchors.append(anchor)
    }
    
    func configureDebugOptions() {
        self.debugOptions = [
            .showStatistics,         // æ˜¾ç¤ºå¸§ç‡å’Œæ€§èƒ½ä¿¡æ¯
            .showWorldOrigin,        // æ˜¾ç¤ºä¸–ç•Œåæ ‡åŸç‚¹
            .showAnchorOrigins,      // æ˜¾ç¤º Anchor åŸç‚¹
            .showAnchorGeometry,     // æ˜¾ç¤º Anchor æ£€æµ‹å‡ ä½•å›¾å½¢
            .showFeaturePoints,      // æ˜¾ç¤ºç‚¹äº‘ä¿¡æ¯
            .showSceneUnderstanding  // è‹¥ iOS â‰¥ 13.4 ä¸”ä½¿ç”¨ Scene Reconstruction å¯å¯ç”¨
        ]
    }
    
    private func detectWink(faceAnchor: ARFaceAnchor) {
        let blendShapes = faceAnchor.blendShapes
        
        if let leftEyeBlink = blendShapes[.eyeBlinkLeft] as? Float,
           let rightEyeBlink = blendShapes[.eyeBlinkRight] as? Float {
            isWinking = leftEyeBlink > 0.9 && rightEyeBlink > 0.9
        }
    }
    
    private func detectEyebrowRaise(faceAnchor: ARFaceAnchor) {
        let browInnerUp = faceAnchor.blendShapes[.browInnerUp] as? Float ?? 0.0
        let eyebrowRaiseThreshold: Float = 0.1
        isWinking = browInnerUp > eyebrowRaiseThreshold
    }
    
    // MARK: - Kalmanæ»¤æ³¢å™¨ç›¸å…³æ–¹æ³•
    
    /// åº”ç”¨ä¸“é—¨é’ˆå¯¹çœ¨çœ¼ä¼˜åŒ–çš„Kalmanæ»¤æ³¢å™¨
    private func applyKalmanSmoothing(rawPoint: CGPoint, faceAnchor: ARFaceAnchor) -> CGPoint {
        // æ£€æŸ¥smoothingIntensityæ˜¯å¦ä¸º0ï¼Œå¦‚æœæ˜¯åˆ™ä¸è¿›è¡Œå¹³æ»‘
        if smoothingIntensity <= 0.001 {
            return rawPoint
        }
        
        let currentTime = CACurrentMediaTime()
        
        // å¦‚æœè¿™æ˜¯ç¬¬ä¸€æ¬¡æ›´æ–°æˆ–æ—¶é—´é—´éš”è¿‡é•¿ï¼Œé‡ç½®æ»¤æ³¢å™¨
        if lastUpdateTime == 0 || (currentTime - lastUpdateTime) > 0.1 {
            gazeKalmanFilter.reset()
            lastUpdateTime = currentTime
            isSmoothing = false
            
            #if DEBUG
            if arc4random_uniform(100) == 0 {
                print("ğŸ”„ [BLINK-AWARE SMOOTHING] Kalmanæ»¤æ³¢å™¨é‡ç½®")
            }
            #endif
            
            return rawPoint
        }
        
        let deltaTime = Float(currentTime - lastUpdateTime)
        lastUpdateTime = currentTime
        
        // çœ¨çœ¼æ£€æµ‹
        let blendShapes = faceAnchor.blendShapes
        let leftEyeBlink = blendShapes[.eyeBlinkLeft] as? Float ?? 0.0
        let rightEyeBlink = blendShapes[.eyeBlinkRight] as? Float ?? 0.0
        let currentBlinkLevel = max(leftEyeBlink, rightEyeBlink)
        
        // æ›´æ–°æ»¤æ³¢å™¨å‚æ•°ï¼ˆåŸºäºå¹³æ»‘å¼ºåº¦ï¼‰
        let processNoise = 0.005 + (1.0 - smoothingIntensity) * 0.295
        let measurementNoise = baseMeasurementNoise + smoothingIntensity * 28.0
        gazeKalmanFilter.updateParameters(processNoise: processNoise, measurementNoise: measurementNoise)
        
        // ä½¿ç”¨çœ¨çœ¼æ„ŸçŸ¥çš„æ»¤æ³¢å™¨æ›´æ–°
        let smoothedPoint = gazeKalmanFilter.updateWithBlinkAwareness(
            measurement: rawPoint,
            deltaTime: deltaTime,
            blinkLevel: currentBlinkLevel
        )
        
        lastBlinkCheck = currentBlinkLevel
        isSmoothing = true
        
        #if DEBUG
        if arc4random_uniform(600) == 0 {
            let distance = sqrt(pow(smoothedPoint.x - rawPoint.x, 2) + pow(smoothedPoint.y - rawPoint.y, 2))
            let rejectionRate = gazeKalmanFilter.rejectionRate * 100
            print("ğŸ¯ [BLINK-AWARE] å¹³æ»‘å¼ºåº¦:\(String(format: "%.2f", smoothingIntensity)), çœ¨çœ¼ç­‰çº§:\(String(format: "%.2f", currentBlinkLevel)), è·ç¦»å·®:\(String(format: "%.1f", distance))pt, æ‹’ç»ç‡:\(String(format: "%.1f", rejectionRate))%")
        }
        #endif
        
        return smoothedPoint
    }
    
    /// æ ¹æ®smoothingIntensityæ›´æ–°Kalmanæ»¤æ³¢å™¨å‚æ•°
    private func updateKalmanParameters() {
        // å°†smoothingIntensity (0.0-1.0) æ˜ å°„åˆ°åˆé€‚çš„æ»¤æ³¢å™¨å‚æ•°
        // å¢å¼ºç‰ˆæ»¤æ³¢å™¨å¯¹çœ¨çœ¼æ›´æ•æ„Ÿï¼Œéœ€è¦æ›´ç²¾ç»†çš„å‚æ•°è°ƒæ•´
        
        // è¿‡ç¨‹å™ªå£°ï¼šè¾ƒå°çš„å€¼ä½¿ç³»ç»Ÿæ›´ç›¸ä¿¡é¢„æµ‹ï¼Œè¾ƒå¤§çš„å€¼ä½¿ç³»ç»Ÿæ›´ç›¸ä¿¡æµ‹é‡
        // èŒƒå›´ï¼š0.005 (å¼ºå¹³æ»‘) åˆ° 0.3 (å¼±å¹³æ»‘)
        let processNoise = 0.005 + (1.0 - smoothingIntensity) * 0.295
        
        // æµ‹é‡å™ªå£°ï¼šè¾ƒå¤§çš„å€¼ä½¿ç³»ç»Ÿæ›´ç›¸ä¿¡é¢„æµ‹ï¼Œè¾ƒå°çš„å€¼ä½¿ç³»ç»Ÿæ›´ç›¸ä¿¡æµ‹é‡
        // èŒƒå›´ï¼š2.0 (å¼±å¹³æ»‘) åˆ° 30.0 (å¼ºå¹³æ»‘)
        let measurementNoise = 2.0 + smoothingIntensity * 28.0
        
        gazeKalmanFilter.updateParameters(
            processNoise: processNoise,
            measurementNoise: measurementNoise
        )
    }
    
    /// é‡ç½®Kalmanæ»¤æ³¢å™¨ï¼ˆåœ¨å¼€å§‹æ–°çš„è¿½è¸ªä¼šè¯æ—¶è°ƒç”¨ï¼‰
    func resetKalmanFilter() {
        gazeKalmanFilter.reset()
        lastUpdateTime = 0
        isSmoothing = false
        
        #if DEBUG
        print("ğŸ”„ [SMOOTHING] Kalmanæ»¤æ³¢å™¨æ‰‹åŠ¨é‡ç½®")
        #endif
    }
    
    @MainActor @preconcurrency required dynamic init?(coder decoder: NSCoder) {
        fatalError("init(coder:) has not been implemented")
    }
    
    @MainActor @preconcurrency required dynamic init(frame frameRect: CGRect) {
        fatalError("init(frame:) has not been implemented")
    }
}
