//  ARViewContainer.swift
//  Eye-Tracker
//
//  Created by Haoran Zhang on 03/07 2025.
//
//  A AR view container that handles face tracking and eye gaze detection
//  This component integrates ARKit face tracking to enable eye gaze tracking
//  and facial expression detection features
//

import SwiftUI
import ARKit
import RealityKit

struct ARViewContainer: UIViewRepresentable {
    @Binding var eyeGazeActive: Bool
    @Binding var lookAtPoint: CGPoint?
    @Binding var isWinking: Bool
    @StateObject var calibrationManager: CalibrationManager  // Ê∑ªÂä†Ê†°ÂáÜÁÆ°ÁêÜÂô®
    
    func makeUIView(context: Context) -> CustomARView {
        return CustomARView(
            eyeGazeActive: $eyeGazeActive,
            lookAtPoint: $lookAtPoint,
            isWinking: $isWinking,
            calibrationManager: calibrationManager
        )
    }
    
    func updateUIView(_ uiView: CustomARView, context: Context) {}
}

class CustomARView: ARView, ARSessionDelegate {
    @Binding var eyeGazeActive: Bool
    @Binding var lookAtPoint: CGPoint?
    @Binding var isWinking: Bool
    var calibrationManager: CalibrationManager
    
    init(eyeGazeActive: Binding<Bool>,
         lookAtPoint: Binding<CGPoint?>,
         isWinking: Binding<Bool>,
         calibrationManager: CalibrationManager) {
        self.calibrationManager = calibrationManager
        _eyeGazeActive = eyeGazeActive
        _lookAtPoint = lookAtPoint
        _isWinking = isWinking
        super.init(frame: .zero)
        //self.debugOptions = [.showAnchorOrigins]
        self.session.delegate = self
        calibrationManager.arView = self  // Â∞ÜARView‰º†ÈÄíÁªôÊ†°ÂáÜÁÆ°ÁêÜÂô®
        let configuration = ARFaceTrackingConfiguration()
        self.session.run(configuration)
    }
    
    func session(_ session: ARSession, didUpdate anchors: [ARAnchor]) {
        guard let faceAnchor = anchors.compactMap({ $0 as? ARFaceAnchor }).first else {
            return
        }
        
        // Â¶ÇÊûúÂú®Ê†°ÂáÜÊ®°Âºè‰∏ãÔºåÊî∂ÈõÜÊ†°ÂáÜÊï∞ÊçÆ
        if calibrationManager.isCalibrating {
            calibrationManager.collectGazeVector(from:faceAnchor)
        }
        
        // Êõ¥Êñ∞lookAtPointÔºàÊó†ËÆ∫Âú®‰ªÄ‰πàÊ®°Âºè‰∏ãÔºâ
        updateDetectGazePoint(faceAnchor: faceAnchor)
        
        // Â¶ÇÊûúÂú®ÊµãÈáèÊ®°Âºè‰∏ãÔºåÊî∂ÈõÜÊµãÈáèÊï∞ÊçÆ
        if calibrationManager.isMeasuring && calibrationManager.showCalibrationPoint {
            if let point = lookAtPoint {
                calibrationManager.collectMeasurementPoint(point)
            }
        }
        
        // Â¶ÇÊûúÂú®ËøΩË∏™Ê®°Âºè‰∏ãÔºå‰ΩøÁî®Ê†°ÂáÜÂêéÁöÑÊ®°Âûã
        if eyeGazeActive {
            if calibrationManager.calibrationCompleted{
                print("Â∑≤ÁªèÂÆåÊàê‰∫ÜÊ†°ÂáÜÔºåÂºÄÂßãËøΩË∏™Ê®°Âºè")
                calibrationManager.predictScreenPoint(from:faceAnchor)

            } else {
                // Â¶ÇÊûúÊ≤°ÊúâÊ†°ÂáÜÊàñÊ†°ÂáÜÂ§±Ë¥•Ôºå‰ΩøÁî®ÂéüÂßãÂùêÊ†áËÆ°ÁÆóÊñπÊ≥ï
                print("Ê≤°ÊúâÂÆåÊàêÊ†°ÂáÜÔºå‰ΩøÁî®ÂéüÂßãÂùêÊ†áËÆ°ÁÆóÊñπÊ≥ï")
                updateDetectGazePoint(faceAnchor: faceAnchor)
            }
        }
        // ÊòæÁ§∫Ê≥®ËßÜÂêëÈáè
        // self.showLocalLookVector(from: faceAnchor)        
        detectWink(faceAnchor: faceAnchor)
        detectEyebrowRaise(faceAnchor: faceAnchor)
    }
    
    //‰ΩøÁî®ÈáçËΩΩÁöÑÊñπÊ≥ï‰ΩøÂæóÂÖÅËÆ∏‰º†ÂÖ•Ëá™ÂÆö‰πâÂêëÈáè
    func detectGazePoint(faceAnchor: ARFaceAnchor)->CGPoint {
        let lookAtPoint = faceAnchor.lookAtPoint
        let focusPoint=detectGazePoint(faceAnchor: faceAnchor, overrideLookAtPoint: lookAtPoint)
        return focusPoint
    }

    func detectGazePoint(faceAnchor: ARFaceAnchor, overrideLookAtPoint: SIMD3<Float>)-> CGPoint {
        // get the lookAtPoint from faceAnchor local coordinate
        let lookAtPoint = overrideLookAtPoint
        guard let cameraTransform = session.currentFrame?.camera.transform else {
            return .zero
        }
        
        // convert the lookAtPoint from local coordinate into world coordinate
        let lookAtPointInWorld = faceAnchor.transform * simd_float4(lookAtPoint, 1)

        // convert the lookAtPoint from world coordinate into camera coordinate
        let lookAtPointInCamera = simd_mul(simd_inverse(cameraTransform), lookAtPointInWorld)
        
        // ËÆ°ÁÆófocus pointÂú®ÊâãÊú∫Â±èÂπïÁöÑÂùêÊ†áÔºà‰ªÖÁ´ñÂ±èÊ®°ÂºèÔºâ
        let screenX = lookAtPointInCamera.y / (Float(Device.screenSize.width) / 2) * Float(Device.frameSize.width)
        let screenY = lookAtPointInCamera.x / (Float(Device.screenSize.height) / 2) * Float(Device.frameSize.height)
        
        let focusPoint = CGPoint(
            x: CGFloat(screenX).clamped(to: Ranges.widthRange),
            y: CGFloat(screenY).clamped(to: Ranges.heightRange)
        )
        return focusPoint
    }
    // ÂØπlookAtPointËøõË°åÂ±èÂπïÊ†°ÂáÜÔºàAR‰ª•Âè≥‰∏äËßí‰∏∫ÂéüÁÇπÔºåUIkit‰ª•Â∑¶‰∏äËßíÂõ†Ê≠§ÈúÄË¶ÅÂØπÊç¢Ôºâ
    func adjustScreenPoint(_ point: CGPoint) -> CGPoint {
        guard let orientation = UIApplication.shared.windows.first?.windowScene?.interfaceOrientation else {
            return point
        }

        let size = UIScreen.main.bounds.size
        let adjusted: CGPoint

        // UIKit ‰ª•Â∑¶‰∏äËßí‰∏∫ÂéüÁÇπÔºåARKit ‰ª•Âè≥‰∏äËßí‰∏∫ÂéüÁÇπÔºåÊñπÂêëÈúÄËΩ¨Êç¢
        switch orientation {
        case .landscapeRight, .landscapeLeft:
            adjusted = CGPoint(x: size.width - point.x, y: size.height - point.y)
        case .portrait, .portraitUpsideDown:
            adjusted = CGPoint(x: size.width - point.x, y: size.height - point.y)
        default:
            assertionFailure("Unknown orientation")
            return point
        }

        return adjusted
    }
    func updateCGPoint(faceAnchor: ARFaceAnchor) -> CGPoint {
        guard let frame = self.session.currentFrame else { return .zero }
        guard let orientation = UIApplication.shared.windows.first?.windowScene?.interfaceOrientation else { return .zero }

        let lookAtVector = faceAnchor.lookAtPoint
        let worldLookAt = faceAnchor.transform * SIMD4<Float>(lookAtVector, 1)

        let projected = frame.camera.projectPoint(
            SIMD3<Float>(worldLookAt.x, worldLookAt.y, worldLookAt.z),
            orientation: orientation,
            viewportSize: UIScreen.main.bounds.size
        )

        // ‚úÖ ÂÖ≥ÈîÆÔºö‰∫∫‰∏∫Áº©Êîæ‰ª•Â¢ûÂº∫ÂèØËßÜÂìçÂ∫î
        let scaleFactor: CGFloat = 9 // Êé®Ëçê 1.5ÔΩû3.0
        let center = CGPoint(x: UIScreen.main.bounds.midX, y: UIScreen.main.bounds.midY)
        let relative = CGPoint(x: projected.x - center.x, y: projected.y - center.y)

        let scaled = CGPoint(
            x: center.x + relative.x * scaleFactor,
            y: center.y + relative.y * scaleFactor
        )
        let adjusted = adjustScreenPoint(scaled)

        let clamped = CGPoint(
            x: adjusted.x.clamped(to: Ranges.widthRange),
            y: adjusted.y.clamped(to: Ranges.heightRange)
        )

        DispatchQueue.main.async {
            self.lookAtPoint = clamped
        }

        return clamped
    }



    func updateDetectGazePoint(faceAnchor: ARFaceAnchor){
        let focusPoint=detectGazePoint(faceAnchor: faceAnchor)
        DispatchQueue.main.async {
            self.lookAtPoint = focusPoint
        }
    }
    func updateDetectGazePoint(faceAnchor: ARFaceAnchor,overrideLookAtPoint: SIMD3<Float>){
        let focusPoint=detectGazePoint(faceAnchor: faceAnchor,overrideLookAtPoint: overrideLookAtPoint)
        DispatchQueue.main.async {
            self.lookAtPoint = focusPoint
        }
    }
    
    private func detectWink(faceAnchor: ARFaceAnchor) {
        let blendShapes = faceAnchor.blendShapes
        
        if let leftEyeBlink = blendShapes[.eyeBlinkLeft] as? Float,
           let rightEyeBlink = blendShapes[.eyeBlinkRight] as? Float {
            isWinking = leftEyeBlink > 0.9 && rightEyeBlink > 0.9
        }
    }
    
    private func detectEyebrowRaise(faceAnchor: ARFaceAnchor) {
        let browInnerUp = faceAnchor.blendShapes[.browInnerUp] as? Float ?? 0.0
        let eyebrowRaiseThreshold: Float = 0.1
        isWinking = browInnerUp > eyebrowRaiseThreshold
    }
    // 4debug ÊòæÁ§∫faceAnchorÁöÑgazeÂ∞ÑÁ∫ø
    /// ÂèØËßÜÂåñ faceAnchor ÁöÑÂ±ÄÈÉ®Ê≥®ËßÜÂêëÈáèÔºàÁõ∏ÂØπ‰∫é face ÂéüÁÇπÔºâ
    /*
    func showLocalLookVector(from faceAnchor: ARFaceAnchor) {
        if let oldAnchor = self.scene.anchors.first(where: { $0.name == "localLookVectorAnchor" }) {
            self.scene.anchors.remove(oldAnchor)
        }

        let localLookAt = faceAnchor.lookAtPoint
        let vectorLength = simd_length(localLookAt)
        guard vectorLength > 0.001 else { return }

        // üü¢ Ëµ∑ÁÇπÁêÉ‰ΩìÔºàface local ÂéüÁÇπÔºâ
        let startSphere = ModelEntity(
            mesh: .generateSphere(radius: 0.006),
            materials: [SimpleMaterial(color: .green, isMetallic: false)]
        )
        startSphere.position = [0, 0, 0]

        // ‚úÖ Â∞ÜÁêÉ‰ΩìÊ∑ªÂä†Âà∞‰ª• faceAnchor.transform ‰∏∫ÂèòÊç¢ÁöÑ anchor ‰∏ä
        let anchor = AnchorEntity()
        anchor.transform.matrix = faceAnchor.transform
        anchor.name = "localLookVectorAnchor"
        anchor.addChild(startSphere)

        self.scene.anchors.append(anchor)

        print("üü¢ ÊòæÁ§∫ face ÂéüÁÇπÁêÉ‰Ωì ‚úÖ gazeLength=\(vectorLength)")
    }
    */

    @MainActor required dynamic init?(coder decoder: NSCoder) {
        fatalError("init(coder:) has not been implemented")
    }
    
    @MainActor required dynamic init(frame frameRect: CGRect) {
        fatalError("init(frame:) has not been implemented")
    }
}
